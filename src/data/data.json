{
  "name": "Start",
  "children": [
    {
      "name": "Requirement definition",
      "children": [
        {
          "name": "Retraining model",
          "children": [
            {
              "name": "data to avoid overfitting",
              "id": 300,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 200,
          "level": 2
        },
        {
          "name": "External services",
          "children": [
            {
              "name": "randomly randomly to balance data",
              "id": 301,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 201,
          "level": 2
        },
        {
          "name": "Metric selection",
          "children": [
            {
              "name": "randomly randomly to balance data2",
              "id": 302,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 202,
          "level": 2
        },
        {
          "name": "Probabilistic model",
          "children": [
            {
              "name": "only on training",
              "id": 303,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 203,
          "level": 2
        }
      ],
      "id": 100,
      "level": 1
    },
    {
      "name": "EDA",
      "children": [
        {
          "name": "Define types of features and  dependencies between them",
          "children": [
            {
              "name": "training imputation on validation and test datasets",
              "id": 304,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "noisy data",
              "id": 305,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 204,
          "level": 2
        },
        {
          "name": "Detect trends, errors  and relations in data",
          "children": [
            {
              "name": "depedant and independant variables",
              "id": 306,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "right type for each feature",
              "id": 307,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "order of a feature if required when clustering is applied",
              "id": 308,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "Categorical multiple binary",
              "id": 309,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "datetime features with sine/cosine facets",
              "id": 310,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 205,
          "level": 2
        }
      ],
      "id": 101,
      "level": 1
    },
    {
      "name": "DATA",
      "children": [
        {
          "name": "Improve performance",
          "children": [
            {
              "name": "datetime features with frequencies or general features",
              "id": 311,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 206,
          "level": 2
        },
        {
          "name": "Prevent computation of  biased metrics and avoid overfitting",
          "children": [
            {
              "name": "image 2 2d array",
              "id": 312,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "dataset for regression when data is dependable on categorical data",
              "id": 313,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 207,
          "level": 2
        },
        {
          "name": "Dataset construction",
          "children": [
            {
              "name": "datetime into four features",
              "id": 314,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "image crop object of interest to detect",
              "id": 315,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "image 2 characters",
              "id": 316,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "image 2 characters2",
              "id": 317,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "data based on algorithms",
              "id": 318,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "data relu",
              "id": 319,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "based on algorithm and data",
              "id": 320,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 208,
          "level": 2
        },
        {
          "name": "Ensure minimum size and how to measure the size",
          "children": [
            {
              "name": "when model sensitive magnitude",
              "id": 321,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "when using SVM",
              "id": 322,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "with training statistics",
              "id": 323,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 209,
          "level": 2
        }
      ],
      "id": 102,
      "level": 1
    },
    {
      "name": "Labeling",
      "children": [
        {
          "name": "Scalability",
          "children": [
            {
              "name": "data",
              "id": 324,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 210,
          "level": 2
        },
        {
          "name": "Parametrize",
          "children": [
            {
              "name": "all datasets with training statistics",
              "id": 325,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 211,
          "level": 2
        }
      ],
      "id": 103,
      "level": 1
    },
    {
      "name": "Feature selection",
      "children": [
        {
          "name": "Consider existing techniques and their assumptions",
          "children": [
            {
              "name": "directional statistics to handle geo data",
              "id": 326,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "average word embeding when using set invariant to permutation",
              "id": 327,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "geodesic distance to predict geo data",
              "id": 328,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "manifold learning methods for unsupervised feature engineering",
              "id": 329,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "dummy data when having categorical data in regression",
              "id": 330,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "cyclical features to encode date/time",
              "id": 331,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "oversample after samplingdata",
              "id": 332,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "imputation techiques when missing data",
              "id": 333,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "existing routines for data cleaning",
              "id": 334,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "using hashing and salt",
              "id": 335,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "invariant algorithms when having mixed data",
              "id": 336,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "data based on algorithms",
              "id": 337,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 212,
          "level": 2
        },
        {
          "name": "General ",
          "children": [
            {
              "name": "data",
              "id": 338,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "all numeric features",
              "id": 339,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 213,
          "level": 2
        }
      ],
      "id": 104,
      "level": 1
    },
    {
      "name": "Wrangling",
      "children": [
        {
          "name": "Transform  numerical features",
          "children": [
            {
              "name": "all numeric features2",
              "id": 340,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "geoloccation data to deduce information",
              "id": 341,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "a superset vocabulary",
              "id": 342,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "features only on train data",
              "id": 343,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "different selection techniques",
              "id": 344,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 214,
          "level": 2
        },
        {
          "name": "Transform non numerical data",
          "children": [
            {
              "name": "dimensionality reduction",
              "id": 345,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "pca assumptions hold",
              "id": 346,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 215,
          "level": 2
        },
        {
          "name": "Transform misellaneous data type",
          "children": [
            {
              "name": "Backward or forward selection independently any classifier",
              "id": 347,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "dimensionality reduction technique",
              "id": 348,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 216,
          "level": 2
        },
        {
          "name": "Augment dataset",
          "children": [
            {
              "name": "elastic net when high collinearity",
              "id": 349,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 217,
          "level": 2
        },
        {
          "name": "Encode non numerical data",
          "children": [
            {
              "name": "lasso regularization",
              "id": 350,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "mutual information",
              "id": 351,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "regularization in algorithms",
              "id": 352,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "variable important index given by random forest",
              "id": 353,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 218,
          "level": 2
        },
        {
          "name": "Encode misellaneous",
          "children": [
            {
              "name": "latent variables",
              "id": 354,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "lasso ridge or glmnet when doing multiple regression",
              "id": 355,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 219,
          "level": 2
        },
        {
          "name": "Encode numerical data",
          "children": [
            {
              "name": "ROC for evaluating hypotesis for specific feature",
              "id": 356,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 220,
          "level": 2
        },
        {
          "name": "Impute missing data",
          "children": [
            {
              "name": "p value greater than 0.5 in logistic regression",
              "id": 357,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 221,
          "level": 2
        },
        {
          "name": "Balance data",
          "children": [
            {
              "name": "multivariate over univariate",
              "id": 358,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "multivariate over univariate2",
              "id": 359,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "multivariate over univariate3",
              "id": 360,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 222,
          "level": 2
        },
        {
          "name": "Eliminate noisy data",
          "children": [
            {
              "name": "data errors",
              "id": 361,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 223,
          "level": 2
        },
        {
          "name": "Prepare dataset",
          "children": [
            {
              "name": "time trends",
              "id": 362,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 224,
          "level": 2
        }
      ],
      "id": 105,
      "level": 1
    },
    {
      "name": "Implementation",
      "children": [
        {
          "name": "Reproducibility/replicability",
          "children": [
            {
              "name": "missing values",
              "id": 363,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "missing values2",
              "id": 364,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "missing values3",
              "id": 365,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 225,
          "level": 2
        },
        {
          "name": "Documentation/traceability",
          "children": [
            {
              "name": "bayesian optimization",
              "id": 366,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "compare training test performance",
              "id": 367,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 226,
          "level": 2
        },
        {
          "name": "Consistency/Integrity",
          "children": [
            {
              "name": "cross validation",
              "id": 368,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 227,
          "level": 2
        },
        {
          "name": "Resources usage",
          "children": [
            {
              "name": "nested cross validation",
              "id": 369,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "model selection performed separately in each trial",
              "id": 370,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "by using multiple randomised partitionings of the available data",
              "id": 371,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "use hold out if crossvalidation is for verification",
              "id": 372,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "introduce unwanted confounding between origins and seasonality",
              "id": 373,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 228,
          "level": 2
        }
      ],
      "id": 106,
      "level": 1
    },
    {
      "name": "Validation",
      "children": [
        {
          "name": "Things to consider when evaluating a model",
          "children": [
            {
              "name": "performance over a wide range of datasets",
              "id": 374,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "algorithms time vs accuracy",
              "id": 375,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "model in test set after cross-validation for hyperparameter tuning",
              "id": 376,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "with nested-crossvalidation when desirable lower random uncertainty",
              "id": 377,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "dataset samples time vs accuracy",
              "id": 378,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "hyperparameter in valdation set",
              "id": 379,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "classifiers independently when using ensemble",
              "id": 380,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "learning curves",
              "id": 381,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "metrics based on goal",
              "id": 382,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "model based on test set",
              "id": 383,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "derivates of cost function when objectives functions slow or do not converge",
              "id": 384,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "metrics at the end of epoch",
              "id": 385,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "best hyperparameters on test set",
              "id": 386,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "vocabulary from training set when using crossvalidation",
              "id": 387,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "cost function",
              "id": 388,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "crossvalidation instead training test split",
              "id": 389,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "crossvalidation when data insuficient to split in training validation testing",
              "id": 390,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "nested-crossvalidation instead training test split",
              "id": 391,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 229,
          "level": 2
        },
        {
          "name": "Hyper parameter tuning",
          "children": [
            {
              "name": "random seed to assure reproducibility and fair comparison when training deep neural network",
              "id": 392,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "repeated cross validation with different seed to avoid impact of fixed seed",
              "id": 393,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "several runs of cross validation or bootstrap",
              "id": 394,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "single cross validation and test with several seed to avoid seed impact",
              "id": 395,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 230,
          "level": 2
        },
        {
          "name": "Unit testing",
          "children": [
            {
              "name": "use adversarial inputs for testing",
              "id": 396,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 231,
          "level": 2
        },
        {
          "name": "Avoid overfitting",
          "children": [
            {
              "name": "use annotated data for unit testing",
              "id": 397,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "when using rolling origin on large dataset",
              "id": 398,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "membership new data to training set",
              "id": 399,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "probabilistic model optimization from probability threshold selection",
              "id": 400,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "model is not biased when building superset vocabulary",
              "id": 401,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "model is not biased when building superset vocabulary2",
              "id": 402,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 232,
          "level": 2
        }
      ],
      "id": 107,
      "level": 1
    },
    {
      "name": "Deployment",
      "children": [
        {
          "name": "Avoid overfitting",
          "children": [
            {
              "name": "model is not biased when building superset vocabulary3",
              "id": 403,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "retrain with new observation",
              "id": 404,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 233,
          "level": 2
        }
      ],
      "id": 108,
      "level": 1
    },
    {
      "name": "Training",
      "children": [
        {
          "name": "Select learning rate",
          "children": [
            {
              "name": "retrain with new observation2",
              "id": 405,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "retrain with new observation3",
              "id": 406,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 234,
          "level": 2
        },
        {
          "name": "Retraining models",
          "children": [
            {
              "name": "multiple humans",
              "id": 407,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "tool that fixed aspect ratio for object detection",
              "id": 408,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "tool that fixed aspect ratio for object detection3",
              "id": 409,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "efficiency of io",
              "id": 410,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 235,
          "level": 2
        },
        {
          "name": "Convergence",
          "children": [
            {
              "name": "training to optimize time",
              "id": 411,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "pipelines",
              "id": 412,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "resource aware implementations",
              "id": 413,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "separate files",
              "id": 414,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "pipelines to enable reproducibility data preprocessing",
              "id": 415,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 236,
          "level": 2
        },
        {
          "name": "Improve performance",
          "children": [
            {
              "name": "params",
              "id": 416,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            },
            {
              "name": "data deletion in pipeline",
              "id": 417,
              "level": 3,
              "description": "transform data (normalize,standarize,scale) based on the algorithms (e.g., model assumptions, model characteristics, model sensitivity to magnitude)  that will use the data and  the data nature (e.g., data distributions, data types)",
              "pipeline": "pipeline"
            }
          ],
          "id": 237,
          "level": 2
        }
      ],
      "id": 109,
      "level": 1
    }
  ]
}
